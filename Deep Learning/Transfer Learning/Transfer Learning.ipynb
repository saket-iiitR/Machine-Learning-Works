{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Transfer Learning</h1>\n",
    "<h6>Saket Tiwari</h6>\n",
    "Date: 03 Jul 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Conv2D, Activation,Flatten, Dropout, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test)= mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples= 20000\n",
    "x1_train= []\n",
    "x1_test= []\n",
    "y1_train= []\n",
    "y1_test= []\n",
    "\n",
    "x2_train= []\n",
    "x2_test= []\n",
    "y2_train= []\n",
    "y2_test= []\n",
    "\n",
    "for i in range(num_examples):\n",
    "    if y_train[i] <5:\n",
    "        x1_train.append(x_train[i]/ 255)\n",
    "        y1_train.append(y_train[i])\n",
    "    else:\n",
    "        x2_train.append(x_train[i]/ 255)\n",
    "        y2_train.append(y_train[i])\n",
    "        \n",
    "num_of_test_examples=y_test.shape[0]\n",
    "for i in range(num_of_test_examples):\n",
    "    if y_test[i] <5:\n",
    "        x1_test.append(x_test[i]/ 255)\n",
    "        y1_test.append(y_test[i])\n",
    "    else:\n",
    "        x2_test.append(x_test[i]/ 255)\n",
    "        y2_test.append(y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train= np.asarray(x1_train).reshape(-1,28,28,1)\n",
    "X1_test= np.asarray(x1_test).reshape(-1,28,28,1)\n",
    "\n",
    "X2_train= np.asarray(x2_train).reshape(-1,28,28,1)\n",
    "X2_test= np.asarray(x2_test).reshape(-1,28,28,1)\n",
    "\n",
    "Y1_train = np_utils.to_categorical(np.asarray(y1_train), num_classes=5)\n",
    "Y1_test = np_utils.to_categorical(np.asarray(y1_test), num_classes=5)\n",
    "\n",
    "Y2_train = np_utils.to_categorical(np.asarray(y2_train), num_classes=10)\n",
    "Y2_test = np_utils.to_categorical(np.asarray(y2_test), num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10225, 28, 28, 1) (5139, 28, 28, 1)\n",
      "(10225, 5) (5139, 5)\n",
      "(9775, 28, 28, 1) (4861, 28, 28, 1)\n",
      "(9775, 10) (4861, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X1_train.shape, X1_test.shape)\n",
    "print(Y1_train.shape, Y1_test.shape)\n",
    "\n",
    "print(X2_train.shape, X2_test.shape)\n",
    "print(Y2_train.shape, Y2_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 20, 20, 16)        12816     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 10, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 8)           1160      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 81,117\n",
      "Trainable params: 81,117\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(32,5, input_shape=(28,28,1), activation='relu'))\n",
    "\n",
    "model.add(Conv2D(16,5, activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(8,3,activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#output layer\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:05.013886\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "start=datetime.datetime.now()\n",
    "time.sleep(5)\n",
    "end=datetime.datetime.now()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0703 12:05:53.186249 10688 deprecation.py:323] From c:\\users\\professionally_saket\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10225 samples, validate on 5139 samples\n",
      "Epoch 1/10\n",
      " - 11s - loss: 0.2919 - acc: 0.8989 - val_loss: 0.0481 - val_acc: 0.9860\n",
      "Epoch 2/10\n",
      " - 11s - loss: 0.0761 - acc: 0.9756 - val_loss: 0.0343 - val_acc: 0.9916\n",
      "Epoch 3/10\n",
      " - 11s - loss: 0.0596 - acc: 0.9807 - val_loss: 0.0215 - val_acc: 0.9934\n",
      "Epoch 4/10\n",
      " - 11s - loss: 0.0486 - acc: 0.9853 - val_loss: 0.0205 - val_acc: 0.9955\n",
      "Epoch 5/10\n",
      " - 11s - loss: 0.0372 - acc: 0.9886 - val_loss: 0.0131 - val_acc: 0.9955\n",
      "Epoch 6/10\n",
      " - 11s - loss: 0.0340 - acc: 0.9892 - val_loss: 0.0132 - val_acc: 0.9955\n",
      "Epoch 7/10\n",
      " - 11s - loss: 0.0263 - acc: 0.9912 - val_loss: 0.0092 - val_acc: 0.9963\n",
      "Epoch 8/10\n",
      " - 11s - loss: 0.0216 - acc: 0.9929 - val_loss: 0.0103 - val_acc: 0.9965\n",
      "Epoch 9/10\n",
      " - 11s - loss: 0.0213 - acc: 0.9933 - val_loss: 0.0128 - val_acc: 0.9955\n",
      "Epoch 10/10\n",
      " - 11s - loss: 0.0203 - acc: 0.9931 - val_loss: 0.0117 - val_acc: 0.9963\n",
      "0:01:53.836165\n"
     ]
    }
   ],
   "source": [
    "start=datetime.datetime.now()\n",
    "\n",
    "model.fit(X1_train,Y1_train,epochs=10,shuffle=True,batch_size=100, verbose=2, validation_data=(X1_test, Y1_test))\n",
    "\n",
    "\n",
    "end=datetime.datetime.now()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN ko fir se train nahi karna h, isliye humlog usko false karenge\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#Hmara 6 transferable layer h, jinke weights humlogon ko update nahi karna h, isse model fast ho jayga\n",
    "for layer in model.layers[:6]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers:\n",
    "    print(layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 20, 20, 16)        12816     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 10, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 8)           1160      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 81,762\n",
      "Trainable params: 66,954\n",
      "Non-trainable params: 14,808\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#humlog transfer model tyaar karenge yaha par\n",
    "trans_model= Sequential(model.layers[:6])\n",
    "trans_model.add(Dense(128))\n",
    "trans_model.add(Activation('relu'))\n",
    "\n",
    "#output\n",
    "trans_model.add(Dense(10))\n",
    "trans_model.add(Activation('softmax'))\n",
    "\n",
    "trans_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9775 samples, validate on 4861 samples\n",
      "Epoch 1/10\n",
      " - 6s - loss: 0.3187 - acc: 0.8975 - val_loss: 0.0909 - val_acc: 0.9735\n",
      "Epoch 2/10\n",
      " - 5s - loss: 0.1136 - acc: 0.9640 - val_loss: 0.0661 - val_acc: 0.9784\n",
      "Epoch 3/10\n",
      " - 5s - loss: 0.0882 - acc: 0.9706 - val_loss: 0.0565 - val_acc: 0.9825\n",
      "Epoch 4/10\n",
      " - 5s - loss: 0.0764 - acc: 0.9774 - val_loss: 0.0499 - val_acc: 0.9848\n",
      "Epoch 5/10\n",
      " - 5s - loss: 0.0715 - acc: 0.9760 - val_loss: 0.0485 - val_acc: 0.9852\n",
      "Epoch 6/10\n",
      " - 5s - loss: 0.0692 - acc: 0.9777 - val_loss: 0.0493 - val_acc: 0.9840\n",
      "Epoch 7/10\n",
      " - 5s - loss: 0.0561 - acc: 0.9814 - val_loss: 0.0430 - val_acc: 0.9858\n",
      "Epoch 8/10\n",
      " - 5s - loss: 0.0551 - acc: 0.9827 - val_loss: 0.0410 - val_acc: 0.9864\n",
      "Epoch 9/10\n",
      " - 5s - loss: 0.0523 - acc: 0.9834 - val_loss: 0.0414 - val_acc: 0.9864\n",
      "Epoch 10/10\n",
      " - 5s - loss: 0.0463 - acc: 0.9848 - val_loss: 0.0378 - val_acc: 0.9866\n",
      "0:00:47.019365\n"
     ]
    }
   ],
   "source": [
    "start=datetime.datetime.now()\n",
    "\n",
    "trans_model.fit(X2_train,Y2_train,epochs=10,shuffle=True,batch_size=100, verbose=2, validation_data=(X2_test, Y2_test))\n",
    "\n",
    "\n",
    "end=datetime.datetime.now()\n",
    "print(end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
